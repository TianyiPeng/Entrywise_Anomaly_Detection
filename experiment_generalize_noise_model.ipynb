{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "import time\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.optimize import minimize\n",
    "from scipy import sparse\n",
    "import os.path\n",
    "from scipy.interpolate import splrep, splev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose M is the underlying matrix, X is the observed matrix. Noise to signal ratio is denoted by\n",
    "$$\n",
    "\\sqrt{\\frac{\\|P_{\\Omega}(X-M)\\|_{F}^2}{\\|P_{\\Omega}(M)\\|_{F}^2}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_to_signal(X, M, Ω):\n",
    "    return np.sqrt(np.sum((Ω*X - Ω*M)**2) / np.sum((Ω*M)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_mean(X, M, Ω):\n",
    "    return np.sum(np.abs((X-M)*Ω)) / np.sum(Ω)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_Frobenious(Mhat, M):\n",
    "    return np.sqrt(np.sum((Mhat - M)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_max(Mhat, M):\n",
    "    return np.max(np.abs(Mhat - M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_AUC(FPR, TPR):\n",
    "    return np.sum((TPR[1:] + TPR[:-1])*(FPR[1:]-FPR[:-1])/2)\n",
    "\n",
    "#unit_test of count_AUC\n",
    "#FPR = np.linspace(0, 1, 100)\n",
    "#TPR = 1 - (1-FPR)**2 \n",
    "#print(count_AUC(FPR, TPR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns\n",
    "$$\n",
    "SVD(M)_r\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## least-squares solved via single SVD\n",
    "def SVD(M,r): #input matrix M, approximating with rank r\n",
    "    u,s,vh = np.linalg.svd(M, full_matrices=False) #s is diag\n",
    "    X = u[:,:r].dot(np.diag(np.sqrt(s[:r])))\n",
    "    Y = vh[:r,:].T.dot(np.diag(np.sqrt(s[:r])))\n",
    "    return X.dot(Y.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns $$\\operatorname{argmin}_A \\|A\\|_1 + \\gamma\\|P_\\Omega (A - X)\\|_F^2$$\n",
    "\n",
    "Indeed\n",
    "\\begin{align}\n",
    "A_{ij} = \\begin{cases} 0 & if |X_{ij}| < \\frac{1}{2\\gamma}~or~(i,j) \\notin \\Omega \\\\ (X_{ij} - sign(X_{ij})\\frac{1}{2\\gamma}) & otherwise \\end{cases} \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_prox(X,Ω,γ):\n",
    "    return Ω * np.sign(X) * np.maximum(0,np.abs(X)-.5/γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns $$\\operatorname{argmin}_M \\|M\\|_* + \\frac{1}{2\\gamma}\\|M - X\\|_F^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_threshold(X,γ):\n",
    "    U,s,VT = np.linalg.svd(X, full_matrices=False)\n",
    "    S_threshold = np.diag(np.maximum(0,s-γ))\n",
    "    return U.dot(S_threshold).dot(VT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns $$\\operatorname{argmin}_M \\|M\\|_* + \\frac{1}{2\\gamma}\\|P_\\Omega(M - X)\\|_F^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_impute(X,Ω,γ,convergence_threshold=.001, debug=False):\n",
    "    M_old = np.zeros(X.shape)\n",
    "    M_new = soft_threshold(Ω*X + (1-Ω)*M_old,γ)\n",
    "    while  np.sum((M_old-M_new)**2) >= convergence_threshold * np.sum(M_old**2):\n",
    "        M_old = M_new\n",
    "        M_new = soft_threshold(Ω*X + (1-Ω)*M_old,γ)\n",
    "        #print(np.sum((M_old-M_new)**2), np.sum(M_old**2))\n",
    "        #print(γ)\n",
    "        if (np.sum(M_old**2)<1e-6):\n",
    "            break\n",
    "        if (debug):\n",
    "            print(np.linalg.matrix_rank(M_new))\n",
    "    return M_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLE estimator of p and alpha:\n",
    "$$\n",
    "\\max_{p, \\alpha} \\sum_{ij} \\log\\left\\{P\\left(X|\\frac{M}{1-p+p*\\alpha}, p, \\alpha\\right)\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an algorithm, if $t_{ij}$ is the probability to claim anomaly at the entry $(i, j)$, then\n",
    "\\begin{align}\n",
    "TPR &= \\frac{\\sum_{ij} t_{ij} P(anomaly|X_{ij}) }{\\sum_{ij} P(anomaly|X_{ij})} \\\\\n",
    "FPR &= \\frac{\\sum_{ij} t_{ij} P(not~~anomaly|X_{ij})}{\\sum_{ij} P(not~~anomaly|X_{ij})}\n",
    "\\end{align}\n",
    "where \n",
    "\\begin{align}\n",
    "P(anomaly|X_{ij}) \n",
    "&= \\frac{p\\frac{(\\alpha M^{*})^{X}}{X!}e^{-\\alpha M^{*}}}{(1-p)\\frac{(M^{*})^{X}}{X!}e^{-M^{*}}+p\\frac{(\\alpha M^{*})^{X}}{X!}e^{-\\alpha M^{*}}}\\\\\n",
    "&= \\frac{p(\\alpha)^{X} e^{-\\alpha M^{*}}}{(1-p)e^{-M^{*}}+p(\\alpha)^{X} e^{-\\alpha M^{*}}} \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_decrease_noise_model:\n",
    "    '''\n",
    "        not done yet\n",
    "    '''\n",
    "\n",
    "    def __init__(self, p, alpha, p_range = (1e-5, 0.4), one_over_exp_range = (1e-5, 0.5)):\n",
    "        self.p = p\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def add_noise(self, M0):\n",
    "\n",
    "        anomaly_set = np.random.binomial(1, self.p, M0.shape)\n",
    "        \n",
    "        A = anomaly_set * self.alpha + (1-anomaly_set)\n",
    "\n",
    "        X = np.random.poisson(M0*A)\n",
    "\n",
    "        return anomaly_set, X\n",
    "\n",
    "    def MLE_estimate(self, M, X, Ω, debug=False):\n",
    "        def f(x):\n",
    "            p = x[0]\n",
    "            alpha = x[1]\n",
    "            M_star = M / (1- p+alpha*p)\n",
    "            A = X*np.log(alpha) + (1-alpha)*M_star\n",
    "            logA = (A<20)*np.log((1-p)+p*np.exp(np.minimum(A, 20))) + (A>=20)*(A+np.log(p))\n",
    "            #print(p, alpha)\n",
    "            #print(- (np.sum(Ω*logA) - np.sum(Ω*X)*np.log(1-p+alpha*p)+np.sum(-Ω*M_star)))\n",
    "            #print(p, alpha, np.sum(Ω*logA), - np.sum(Ω*X)*np.log(1-p+alpha*p), np.sum(-Ω*M_star))\n",
    "            return - (np.sum(Ω*logA) - np.sum(Ω*X)*np.log(1-p+alpha*p) + np.sum(-Ω*M_star))\n",
    "    \n",
    "        \n",
    "        res = minimize(f, (0.5, 0.5), bounds = ((1e-5, 0.5), (1e-5, 0.5)))\n",
    "        print(res)\n",
    "        return res.x[0], res.x[1]\n",
    "\n",
    "    \n",
    "    def posterior_anomaly_processing(self, M, X, Ω):\n",
    "        M = np.maximum(M, 0) + 1e-9\n",
    "        A = X*np.log(self.alpha) + (1-self.alpha)*M\n",
    "        T1 = (A>30)*1e20 + (A<=30)*self.p*np.exp(np.minimum(A, 30))\n",
    "        T3 = Ω * T1 / (T1 + 1-self.p)\n",
    "        return np.reshape(T3, -1)\n",
    "\n",
    "#     def unit_test_MLE_estimator():\n",
    "#     ## Synthetic experiments\n",
    "#     n = 300\n",
    "#     n1 = 300\n",
    "#     n2 = 300\n",
    "#     r = 5\n",
    "#     prob_missing = 1#10.0*r/n\n",
    "#     p = 0.1\n",
    "#     alpha = 0.1\n",
    "#     exp_rate = 10\n",
    "#     mean_value = 3\n",
    "\n",
    "#     #np.random.seed(1)\n",
    "#     U = np.random.gamma(1, 2, (n, r))\n",
    "#     V = np.random.gamma(1, 2, (n, r))\n",
    "#     M0 = U.dot(V.T)\n",
    "#     M0 = M0 / np.mean(M0) * mean_value\n",
    "#     #M0 = np.random.normal(size=(n, r)).dot(np.random.normal(size=(r, n)))\n",
    "#     #u, s, vh = np.linalg.svd(M0, full_matrices=True)\n",
    "#     #print(sorted(s))\n",
    "\n",
    "#     Ω = np.random.binomial(1,prob_missing,(n,n))\n",
    "#     #M0 = M0 * Ω \n",
    "#     #A = np.random.binomial(1,p,(n,n)) * (1-alpha) * M0\n",
    "#     anomaly_set = np.random.binomial(1,p,(n,n))\n",
    "#     A = anomaly_set * np.random.exponential(scale=1/exp_rate, size = (n, n)) + (1-anomaly_set)\n",
    "\n",
    "#     X = np.random.poisson(M0*A)\n",
    "\n",
    "#     print('true p is {} and true exp_rate is {}'.format(p, exp_rate))\n",
    "\n",
    "#     p_est, exp_est = MLE_estimate_exponential_model(M0*(1-p+p/exp_rate), X, Ω, debug=False)\n",
    "#     print('with M0, the p_est is {} and the exp_est is {}'.format(p_est, exp_est))\n",
    "\n",
    "#     M = SVD(X*Ω, r)\n",
    "#     M = np.maximum(M, 1e-8)\n",
    "#     p_est, exp_est = MLE_estimate_exponential_model(M, X, Ω, debug=False)\n",
    "#     print('with SVD, the p_est is {} and the exp_est is {}'.format(p_est, exp_est))\n",
    "\n",
    "#     gamma = 70\n",
    "#     M = soft_impute(X, Ω, gamma,convergence_threshold=1e-5)\n",
    "#     M = np.maximum(M, 1e-8)\n",
    "#     print('with soft_impute, the rank of M is {}, abs mean between M and M0 is {}'.format(np.linalg.matrix_rank(M), abs_mean(M, M0, Ω)))\n",
    "#     p_est, exp_est = MLE_estimate_exponential_model(M, X, Ω, debug=False)\n",
    "#     print('with soft_impute, the p_est is {} and the exp_est is {}'.format(p_est, exp_est))\n",
    "\n",
    "# unit_test_MLE_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exponential_noise_model:\n",
    "\n",
    "    def __init__(self, p, exp_rate, p_range = (1e-5, 0.4), one_over_exp_range = (1e-5, 0.5)):\n",
    "        self.p = p\n",
    "        self.exp_rate = exp_rate\n",
    "        self.p_range = p_range\n",
    "        self.one_over_exp_range = one_over_exp_range\n",
    "\n",
    "    def add_noise(self, M0):\n",
    "\n",
    "        anomaly_set = np.random.binomial(1, self.p, M0.shape)\n",
    "        \n",
    "        A = anomaly_set * np.random.exponential(scale=1/self.exp_rate, size = M0.shape) + (1-anomaly_set)\n",
    "\n",
    "        X = np.random.poisson(M0*A)\n",
    "\n",
    "        return anomaly_set, X\n",
    "\n",
    "    def counting_match_estimate(self, M, X, Ω, debug=False):\n",
    "        def f(x):\n",
    "            p = x[0]\n",
    "            exp_rate = 1/x[1]\n",
    "            M_star = M / (1- p+p/exp_rate)\n",
    "\n",
    "            n0 = np.sum(Ω*(exp_rate / (M_star + exp_rate) * p + (1-p) * np.exp(-M_star))) / np.sum(Ω)\n",
    "            n1 = np.sum(Ω*(exp_rate*M_star / (M_star + exp_rate)**2 * p + (1-p) * np.exp(-M_star)*M_star)) / np.sum(Ω) + n0\n",
    "            n2 = np.sum(Ω*(exp_rate*(M_star**2) / ((M_star + exp_rate)**3) * p + (1-p) * np.exp(-M_star)*(M_star**2)/2)) / np.sum(Ω) + n1\n",
    "\n",
    "            real_n0 = np.sum(Ω*(X==0)) / np.sum(Ω)\n",
    "            real_n1 = np.sum(Ω*(X==1))/ np.sum(Ω) + real_n0\n",
    "            real_n2 = np.sum(Ω*(X==2))/ np.sum(Ω) + real_n1\n",
    "            if (debug):\n",
    "                print(n0, real_n0, n1, real_n1, n2, real_n2)\n",
    "            return np.sqrt((n0-real_n0)**2 + (n1-real_n1)**2 + (n2 - real_n2)**2)\n",
    "        res = minimize(f, (self.p, 1/self.exp_rate), bounds = (self.p_range, self.one_over_exp_range))\n",
    "        print(res)\n",
    "        print('estimate hyper-parameter is p = {}, real_p is {}, exp_rate = {}, real_exp_rate is {}'.format(res.x[0], self.p, 1/res.x[1], self.exp_rate))\n",
    "        return res.x[0], 1/res.x[1]\n",
    "\n",
    "        \n",
    "    def MLE_estimate(self, M, X, Ω, debug=False):\n",
    "        def f(x):\n",
    "            p = x[0]\n",
    "            exp_rate = 1/x[1]\n",
    "            M_star = M / (1- p+p/exp_rate)\n",
    "            A = (X+1)*np.log(M_star+exp_rate) - M_star - scipy.special.gammaln(X+1)\n",
    "            logA = (A<=30)*np.log(p*exp_rate + (1-p)*np.exp(np.minimum(A, 30))) + (A>30)*(A+np.log(1-p))\n",
    "            #print(p, alpha)\n",
    "            #print(- (np.sum(Ω*logA) - np.sum(Ω*X)*np.log(1-p+alpha*p)+np.sum(-Ω*M_star)))\n",
    "            if (debug):\n",
    "                print(p, exp_rate, np.sum(Ω*logA), np.sum(Ω*X*np.log(M_star/(M_star+exp_rate))) , -np.sum(Ω*np.log(M_star+exp_rate)))\n",
    "            return - (np.sum(Ω*logA) + np.sum(Ω*X*np.log(M_star/(M_star+exp_rate))) - np.sum(Ω*np.log(M_star+exp_rate)))\n",
    "\n",
    "        # m_min = 1e9\n",
    "        # for p1 in np.linspace(1e-5, 0.5, num=30):\n",
    "        #     for p2 in np.linspace(1e-5, 0.9, 30):\n",
    "        #         tmp = f([p1, p2])\n",
    "        #         if (tmp < m_min):\n",
    "        #             if (debug):\n",
    "        #                 print(p1, p2, tmp)\n",
    "        #             m_min = tmp\n",
    "        #             ans = [p1, p2]\n",
    "        # return ans[0], 1/ans[1]\n",
    "        # print(ans)\n",
    "        #M = M0*(1-0.3+0.3*0.5)\n",
    "        \n",
    "        res = minimize(f, (0.1, 0.1), bounds = (self.p_range, self.one_over_exp_range))\n",
    "        if (debug):\n",
    "            print(res)\n",
    "            print('estimate hyper-parameter is p = {}, real_p is {}, exp_rate = {}, real_exp_rate is {}'.format(res.x[0], self.p, 1/res.x[1], self.exp_rate))\n",
    "        return res.x[0], 1/res.x[1]\n",
    "\n",
    "    def posterior_anomaly_processing(self, M, X, Ω):\n",
    "        M = np.maximum(M, 0) + 1e-9\n",
    "        A = (X+1)*np.log(M+self.exp_rate) - M - scipy.special.gammaln(X+1)\n",
    "        #some precision trick, we require p*exp_rate / ((1-p)*1e20 + p*exp_rate) \\approx 0\n",
    "        T1 = (A<=50)*(1-self.p)*np.exp(np.minimum(A, 50)) + (A>50)*1e30\n",
    "        T3 = Ω * self.p*self.exp_rate / (T1 + self.p*self.exp_rate)\n",
    "        return np.reshape(T3, T3.shape[0]*T3.shape[1])\n",
    "\n",
    "    \n",
    "    def evaluate_FPR_TPR(self, A_est, M, X, Ω):\n",
    "        M = np.maximum(M, 0) + 1e-9\n",
    "        A = (X+1)*np.log(M+self.exp_rate) - M - scipy.special.gammaln(X+1)\n",
    "        #some precision trick, we require p*exp_rate / ((1-p)*1e20 + p*exp_rate) \\approx 0\n",
    "        T1 = (A<=50)*(1-self.p)*np.exp(np.minimum(A, 50)) + (A>50)*1e30\n",
    "        posterior_anomaly = Ω * self.p*self.exp_rate / (T1 + self.p*self.exp_rate)\n",
    "\n",
    "        TPR = np.sum((A_est != 0) * Ω * posterior_anomaly) / np.sum(Ω * posterior_anomaly)\n",
    "        FPR = np.sum((A_est != 0) * Ω * (1 - posterior_anomaly)) / np.sum(Ω * (1-posterior_anomaly))\n",
    "\n",
    "        return FPR, TPR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    \n",
    "    def __init__(self, n1=1, n2=1, r=1, mean_value=1, prob_observing=1):\n",
    "\n",
    "        self.synthetic_data(n1, n2, r, mean_value, prob_observing)\n",
    "\n",
    "    def synthetic_data(self, n1, n2, r, mean_value, prob_observing):\n",
    "\n",
    "        self.n1 = n1\n",
    "        self.n2 = n2\n",
    "        self.r = r\n",
    "        self.mean_value = mean_value\n",
    "        self.prob_observing = prob_observing\n",
    "        U = np.random.gamma(1, 2, (n1, r))\n",
    "        V = np.random.gamma(1, 2, (n2, r))\n",
    "        M0 = U.dot(V.T)\n",
    "\n",
    "        self.M0 = M0 / np.mean(M0) * mean_value\n",
    "\n",
    "        self.Ω = np.random.binomial(1, prob_observing, (n1,n2))\n",
    "\n",
    "        self.data_type = 'synthetic'\n",
    "\n",
    "    def real_data(self):\n",
    "        ## Real data experiments\n",
    "\n",
    "        M_i = np.genfromtxt('data/wslr_unit_sales_matrix.csv',delimiter=',',filling_values=0)\n",
    "        M_i = M_i[1:, 1:]\n",
    "        Ω = 1-(M_i==0)\n",
    "\n",
    "        rows = np.sum(Ω,axis=1) >= 30\n",
    "        cols = np.sum(Ω,axis=0) >= 30\n",
    "        #print(np.min(np.sum(Ω[rows].T[cols].T,axis=1)))\n",
    "        #print(np.min(np.sum(Ω[rows].T[cols].T,axis=0)))\n",
    "\n",
    "        M_i = M_i[rows].T[cols].T\n",
    "        Ω = Ω[rows].T[cols].T\n",
    "        print(np.sum(M_i)/np.sum(Ω))\n",
    "        print(Ω.shape)\n",
    "        print(np.sum(Ω))\n",
    "        print(np.sum(Ω+1-Ω))\n",
    "\n",
    "        self.M0 = M_i/4\n",
    "        self.n1 = self.M0.shape[0]\n",
    "        self.n2 = self.M0.shape[1]\n",
    "        self.r = 30\n",
    "        self.mean_value = np.sum(self.M0*Ω) / np.sum(Ω)\n",
    "        self.prob_observing = np.sum(Ω) / (self.n1*self.n2)\n",
    "\n",
    "        self.Ω = Ω\n",
    "        self.data_type = 'beer_data'\n",
    "\n",
    "    def add_noise(self, noise_model):\n",
    "        self.anomaly_set, self.X = noise_model.add_noise(self.M0)\n",
    "        self.noise = noise_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of AD algorithm:\n",
    "- Step 1: find $M$ using soft-impute \n",
    "$$\n",
    "M = \\operatorname{argmin}_M \\|M\\|_* + \\frac{1}{2\\gamma}\\|P_\\Omega(M - X)\\|_F^2\n",
    "$$\n",
    "\n",
    "- Step 2: Using $M$ to esitimate $p$ and $\\alpha$ and obtain $\\hat{p}, \\hat{\\alpha}$ (MLE estimator)\n",
    "\n",
    "- Step 3: Using $M, \\hat{p}, \\hat{\\alpha}$ to estimate $P(anomaly|X_{ij})$\n",
    "\n",
    "- Step 4: sorting $P(anomaly|X_{ij})$ from largest to the smallest, and claim the anomaly in this order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(Experiment):\n",
    "\n",
    "    def evaluate_ROC(self, posterior_anomaly, posterior_anomaly_est, Ω):\n",
    "        '''\n",
    "            sorting posterior_anomaly_est (1D array) from the largest to the smallest\n",
    "            using the index to choose posterior_anomaly\n",
    "            only entries in Ω is considered \n",
    "\n",
    "            Assuming the entries in posterior_anomaly_est is bounded by 1e20\n",
    "        ''' \n",
    "        TΩ = np.reshape(Ω, -1)\n",
    "        index = np.argsort(TΩ*(-posterior_anomaly_est) + (1-TΩ)*1e20)\n",
    "        index = index[0:np.sum(Ω)]\n",
    "        sorted_anomaly = posterior_anomaly[index]\n",
    "\n",
    "        TPR = np.cumsum(sorted_anomaly) / np.sum(sorted_anomaly)\n",
    "        FPR = np.cumsum(1-sorted_anomaly) / np.sum(1-sorted_anomaly)\n",
    "        return FPR, TPR\n",
    "\n",
    "    def ideal_ROC(self):\n",
    "        posterior_anomaly = self.noise.posterior_anomaly_processing(self.M0, self.X, self.Ω)\n",
    "        self.FPR_opt, self.TPR_opt = self.evaluate_ROC(posterior_anomaly, posterior_anomaly, self.Ω)\n",
    "        self.posterior_anomaly = posterior_anomaly\n",
    "\n",
    "    def AD_algorithm(self, gamma=1.0, r_constraint = 1e9, debug=False, do_SVD=False, using_ideal_parameter=False):\n",
    "        \n",
    "        if (do_SVD):\n",
    "            M = SVD(self.Ω*self.X, r_constraint)\n",
    "        else:\n",
    "            while (True):\n",
    "                M = soft_impute(self.X, self.Ω, gamma, convergence_threshold=1e-4, debug=debug)\n",
    "                if (np.linalg.matrix_rank(M) > r_constraint):\n",
    "                    gamma = gamma *1.1\n",
    "                    if (debug):\n",
    "                        print('gamma update with the rank ', np.linalg.matrix_rank(M))\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "        M = np.maximum(M, 1e-8)\n",
    "        \n",
    "        #p_est, exp_est = self.noise.counting_match_estimate(M, self.X, self.Ω, debug)\n",
    "        p_est, exp_est = self.noise.MLE_estimate(M, self.X, self.Ω, debug)\n",
    "        if (debug):\n",
    "            print('error between M0 and X', abs_mean(self.X, self.M0, self.Ω))\n",
    "            print('rank of M is', np.linalg.matrix_rank(M))\n",
    "            print('error between M and M0 without correction', abs_mean(M, self.M0, self.Ω))\n",
    "            print('error between M and M0 without correction outside omega', abs_mean(M, self.M0, 1-self.Ω))\n",
    "            print('error between M and M0 with estimated correction', abs_mean(M/(1-p_est+p_est/exp_est), self.M0, self.Ω))\n",
    "            #print('error between M and M0 with correct p and alpha', abs_mean(M/(1-p+p/exp_rate), self.M0, self.Ω))\n",
    "\n",
    "        if (not using_ideal_parameter):\n",
    "            self.posterior_anomaly_est = self.noise.posterior_anomaly_processing(M / (1 - p_est + p_est/exp_est), self.X, self.Ω)\n",
    "        else:\n",
    "            self.posterior_anomaly_est = self.noise.posterior_anomaly_processing(M / (1 - self.noise.p + self.noise.p/self.noise.exp_rate), self.X, self.Ω)\n",
    "\n",
    "        self.FPR_AD, self.TPR_AD = self.evaluate_ROC(self.posterior_anomaly, self.posterior_anomaly_est, self.Ω)\n",
    "        self.p_AD, self.exp_AD = p_est, exp_est\n",
    "        self.M = M / (1 - p_est + p_est/exp_est)\n",
    "\n",
    "    def PCA_with_M(self, M):\n",
    "\n",
    "        self.posterior_anomaly_PCA = np.reshape(self.Ω*(np.abs(self.X-M)+1e-9), -1)\n",
    "        #posterior_anomaly_PCA = np.reshape(Ω*(M0-X+100), -1)\n",
    "        self.FPR_PCA_M0, self.TPR_PCA_M0 = self.evaluate_ROC(self.posterior_anomaly, self.posterior_anomaly_PCA, self.Ω)\n",
    "        return self.FPR_PCA_M0, self.TPR_PCA_M0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of stable_pcp algorithm\n",
    "\n",
    " $$\\operatorname{argmin}_{M,A} \\|M\\|_* + \\lambda\\|A\\|_1 + \\frac{\\mu}{2}\\|P_\\Omega(M + A - X)\\|_F^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(Experiment):\n",
    "\n",
    "    def stable_pcp(self, λ,μ,step_size=1,convergence_threshold=.001, debug=False, up_M = -1, up_A = -1):\n",
    "        num_iter = 0\n",
    "        \n",
    "        X = self.X\n",
    "        Ω = self.Ω\n",
    "\n",
    "        M_old = soft_impute(X,Ω,1/μ)\n",
    "        A_old = l1_prox(X-M_old,Ω,μ/λ/2)\n",
    "        f = 1e20\n",
    "        #for T in range(100):\n",
    "        while (True):\n",
    "            num_iter += 1\n",
    "            G = μ*(M_old+A_old-X)\n",
    "            M_new = soft_impute(M_old-step_size*G,Ω,step_size)\n",
    "            A_new = l1_prox(A_old-step_size*G,Ω,1/2/λ/step_size)\n",
    "            if (up_M > 0):\n",
    "                M_new = np.maximum(np.minimum(M_new, up_M), -up_M)\n",
    "                A_new = np.maximum(np.minimum(A_new, up_A), -up_A)\n",
    "            if np.max(np.abs(M_old-M_new)) < convergence_threshold and np.max(np.abs(A_old-A_new)) < convergence_threshold:\n",
    "                break\n",
    "            else:\n",
    "                M_old, A_old = M_new, A_new\n",
    "                if (num_iter % 1000 == 0):\n",
    "                    break\n",
    "                if (num_iter % 100 == 0):\n",
    "                    f_new = np.linalg.norm(M_new, 'nuc') + λ*np.sum(np.abs(A_new)) + 0.5*μ*np.sum((Ω*(self.X-A_new-M_new))**2)\n",
    "                    if (np.abs(f_new - f) < 1e-3):\n",
    "                        break\n",
    "                    f = f_new\n",
    "                    if (debug):\n",
    "                        print(f)\n",
    "                        print('abs_mean is', abs_mean(M_new, self.M0, Ω), 'deviation is', np.mean(M_new-self.M0))\n",
    "                        print('rank is', np.linalg.matrix_rank(M_new))\n",
    "                        print('step size is', step_size)\n",
    "                \n",
    "                if (num_iter % 10 == 0):\n",
    "                    if (np.linalg.norm(M_new, 'nuc') + λ*np.sum(np.abs(A_new)) + 0.5*μ*np.sum((Ω*(self.X-A_new-M_new))**2) > 1e20):\n",
    "                        step_size = step_size * 0.5\n",
    "                        M_old = soft_impute(X,Ω,1/μ)\n",
    "                        A_old = l1_prox(X-M_old,Ω,μ/λ/2)\n",
    "        if (debug):\n",
    "            print(num_iter)\n",
    "            print(np.linalg.norm(M_new, 'nuc') + λ*np.sum(np.abs(A_new)) + 0.5*μ*np.sum((self.Ω*(self.X-A_new-M_new))**2))\n",
    "            print('rank is', np.linalg.matrix_rank(M_new))\n",
    "        return M_new,A_new\n",
    "\n",
    "    def stable_pcp_withM0(M0, μ, λ):\n",
    "        M_old = M0\n",
    "        A_old = l1_prox(self.X-M_old,self.Ω,μ/λ/2)\n",
    "        return M_old, A_old\n",
    "\n",
    "    def Robust_PCA(self, gamma=50, r_constraint = -1, debug=False, num_points = 5, l_range = (-1, -1), up_M = -1, up_A = -1):\n",
    "        ROC_PCA = [(0, 0), (1, 1)]\n",
    "\n",
    "        if (l_range[0] == -1):\n",
    "            l_range = (0.5, self.mean_value)\n",
    "        numerate = np.linspace(l_range[0], l_range[1], num_points)\n",
    "        self.RPCA_M = []\n",
    "        for ratio in np.concatenate([numerate]):\n",
    "            gamma = gamma * np.log(1+ratio)\n",
    "            flag = 0\n",
    "            while (True):\n",
    "                M_est,A_est = self.stable_pcp(1/gamma*ratio,1/gamma,step_size=50,convergence_threshold=1e-4, debug=False, up_M=up_M, up_A=up_A)\n",
    "                if (debug):\n",
    "                    print('M0-M_est is', abs_mean(M_est, self.M0, self.Ω), 'and gamma is ', gamma, ' and l/mu is', ratio)\n",
    "                    print('rank of M_est is ', np.linalg.matrix_rank(M_est))\n",
    "                if (r_constraint < 0):\n",
    "                    break\n",
    "                if (np.linalg.matrix_rank(M_est) < r_constraint / 2):\n",
    "                    if (flag == -1):\n",
    "                        break\n",
    "                    gamma = gamma / 1.1     \n",
    "                else: \n",
    "                    if (np.linalg.matrix_rank(M_est) > r_constraint):\n",
    "                        gamma = gamma + 0.2\n",
    "                        flag = -1\n",
    "                    else:\n",
    "                        break\n",
    "            gamma = gamma / np.log(1+ratio)\n",
    "            #M_est,A_est = stable_pcp_withM0(X, Ω, ratio/100, 1/((mean_value*n/r/3)*1.7),step_size=50,convergence_threshold=1e-5, debug=True)\n",
    "            #print('M0-M_est is', abs_mean(M_est, self.M0, self.Ω), ' and l/mu is', ratio)\n",
    "            #print('rank of M_est is ', np.linalg.matrix_rank(M_est))\n",
    "            self.RPCA_M.append(M_est)\n",
    "            FPR, TPR = self.noise.evaluate_FPR_TPR(A_est, self.M0, self.X, self.Ω)\n",
    "            print(FPR, TPR)\n",
    "            ROC_PCA.append((FPR, TPR))\n",
    "\n",
    "        ROC_PCA = sorted(ROC_PCA)\n",
    "        self.FPR_PCA = np.array([t[0] for t in ROC_PCA])\n",
    "        self.TPR_PCA = np.array([t[1] for t in ROC_PCA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(Experiment):\n",
    "    def DRMF(self, r, rate_anomalies):\n",
    "        X = self.X\n",
    "        Ω = self.Ω\n",
    "        S = np.zeros_like(X)\n",
    "        L = np.zeros_like(X)\n",
    "        mm = np.sum(Ω)\n",
    "        for t in range(40):\n",
    "            L = SVD(Ω*(X - S - L) + L, r)\n",
    "            #print(np.sort((np.abs(X - L)).reshape(-1)))\n",
    "            thres = np.sort((np.abs(X - L)*Ω + (1-Ω)*1e8).reshape(-1))[int(mm*(1-rate_anomalies))]\n",
    "            S = (X-L)*(np.abs(X-L) >= thres)\n",
    "        self.DRMF_M = L\n",
    "        self.FPR_DRMF, self.TPR_DRMF = self.PCA_with_M(L)\n",
    "        #posterior_anomaly = self.noise.posterior_anomaly_processing(L, self.X, self.Ω)\n",
    "        #self.FPR_DRMF, self.TPR_DRMF = self.evaluate_ROC(posterior_anomaly, self.posterior_anomaly_est, self.Ω)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(Experiment):\n",
    "\n",
    "    def plot_ROC(self):\n",
    "        print(count_AUC(self.FPR_opt, self.TPR_opt))\n",
    "        print(count_AUC(self.FPR_AD, self.TPR_AD))\n",
    "        plt.plot(self.FPR_opt, self.TPR_opt)\n",
    "        plt.plot(self.FPR_AD, self.TPR_AD) \n",
    "        legend_list = [r'$\\pi^{*}$', r'$\\pi^{\\mathrm{EW}}$']\n",
    "        if (hasattr(self, 'FPR_PCA_M0')):\n",
    "            print(count_AUC(self.FPR_PCA_M0, self.TPR_PCA_M0))\n",
    "            plt.plot(self.FPR_PCA_M0, self.TPR_PCA_M0)\n",
    "            legend_list.append('Stable PCP')\n",
    "        if hasattr(self, 'FPR_PCA'):\n",
    "            condition = (self.FPR_PCA <= self.TPR_PCA + 0.01)\n",
    "            print(condition)\n",
    "            print(count_AUC(self.FPR_PCA[condition], self.TPR_PCA[condition]))\n",
    "            plt.plot(self.FPR_PCA[condition], self.TPR_PCA[condition])\n",
    "            legend_list.append('Robust PCA')\n",
    "\n",
    "        plt.legend(legend_list)\n",
    "        plt.xlabel('FPR')\n",
    "        plt.ylabel('TPR')\n",
    "        plt.savefig(self.data_type + '.eps')\n",
    "\n",
    "        f = open('data.npy', 'wb')\n",
    "        np.save(f, self.FPR_opt)\n",
    "        np.save(f, self.TPR_opt)\n",
    "        np.save(f, self.FPR_AD)\n",
    "        np.save(f, self.TPR_AD)\n",
    "        np.save(f, self.FPR_PCA_M0)\n",
    "        np.save(f, self.TPR_PCA_M0)\n",
    "        #plt.title('n = {}, r = {}, mean_value(M*)= {}, p = {}, alpha = {}\\n MLE_p = {:.3f}, MLE_alpha = {:.3f}'.format(n, r, mean_value, p, alpha, p_est, alpha_est))\n",
    "        plt.show()\n",
    "\n",
    "    def generate_data_for_heat_map(self, l1 = 3, l2 = 3, force=False):\n",
    "\n",
    "        if (not force):\n",
    "            return\n",
    "        #if (not force and os.path.isfile('heat_map_data.npy')):\n",
    "        #    return\n",
    "        mean_value_set = np.linspace(0.1, 10, l1)\n",
    "        alpha_set = np.linspace(0.1, 1, l2)\n",
    "\n",
    "        AUC_opt = np.zeros((len(mean_value_set), len(alpha_set)))\n",
    "        AUC_AD = np.zeros((len(mean_value_set), len(alpha_set)))\n",
    "        AUC_PCA = np.zeros((len(mean_value_set), len(alpha_set)))\n",
    "        for (i, mean_value) in enumerate(mean_value_set):\n",
    "            for (j, alpha) in enumerate(alpha_set):\n",
    "                self.synthetic_data(self.n1, self.n2, self.r, mean_value, self.prob_observing)\n",
    "                noise = Exponential_noise_model(p = 0.2, exp_rate = 1/alpha, p_range = (0.01, 0.5), one_over_exp_range=(0.01, 0.8))\n",
    "                self.add_noise(noise)\n",
    "                self.ideal_ROC()\n",
    "                self.AD_algorithm(gamma = (self.n1/self.r)*0.5, r_constraint = self.r, debug=False, do_SVD = False)\n",
    "\n",
    "                \n",
    "\n",
    "                #self.PCA_with_M(self.M0)\n",
    "                self.Robust_PCA(gamma = (self.n2/self.r*0.5), r_constraint=self.r)\n",
    "                #self.PCA_with_M(self.M0+0.3*np.sqrt(self.M0)*np.random.normal(size=self.M0.shape))\n",
    "\n",
    "\n",
    "                AUC_opt[i, j] = count_AUC(self.FPR_opt, self.TPR_opt)\n",
    "                AUC_AD[i, j] = count_AUC(self.FPR_AD, self.TPR_AD)\n",
    "                #AUC_PCA[i, j] = count_AUC(self.FPR_PCA_M0, self.TPR_PCA_M0)\n",
    "                AUC_PCA[i, j] = count_AUC(self.FPR_PCA, self.TPR_PCA)\n",
    "\n",
    "\n",
    "        f = open('heat_map_data.npy', 'wb')\n",
    "        np.save(f, mean_value_set)\n",
    "        np.save(f, alpha_set)\n",
    "        np.save(f, AUC_opt)\n",
    "        np.save(f, AUC_AD)\n",
    "        np.save(f, AUC_PCA)\n",
    "\n",
    "    def plot_heat_map(self, file_path = \"\", file_name = 'heat_map_data'):\n",
    "\n",
    "        def plot_fig(data, title):\n",
    "            sns.heatmap(data, annot=True, xticklabels=alpha_set, yticklabels=mean_value_set)\n",
    "            plt.xlabel(r'$\\alpha$')\n",
    "            plt.ylabel(r'$\\bar{M}^{*}$')\n",
    "            plt.title(title)\n",
    "            plt.savefig(file_path+title+'.eps')\n",
    "            plt.show()  \n",
    "\n",
    "        f = open(file_path+file_name, 'rb')\n",
    "        mean_value_set = np.round(np.load(f), decimals = 2)\n",
    "        alpha_set = np.round(np.load(f), decimals = 2)\n",
    "        AUC_opt = np.load(f)\n",
    "        AUC_AD = np.maximum(np.load(f), 0.5)\n",
    "        AUC_PCA = np.maximum(np.load(f), 0.5)\n",
    "        print(AUC_PCA[0,1])\n",
    "\n",
    "        plot_fig(AUC_opt, 'AUC of ideal')\n",
    "        plot_fig(AUC_AD/AUC_opt, 'AUC of EW over AUC of ideal')\n",
    "        plot_fig(AUC_PCA/AUC_opt, 'AUC of PCA over AUC of ideal')\n",
    "        plot_fig(AUC_AD/AUC_PCA, 'AUC of EW over AUC of PCA')\n",
    "\n",
    "    def plot_heat_map(self, file_path = '', file_name = ''):\n",
    "\n",
    "        def plot_fig(data, title):\n",
    "            sns.heatmap(data, annot=True, xticklabels=alpha_set, yticklabels=mean_value_set)\n",
    "            plt.xlabel(r'$\\alpha$')\n",
    "            plt.ylabel(r'$\\bar{M}^{*}$')\n",
    "            plt.title(title)\n",
    "            plt.savefig(file_path+title+'.eps')\n",
    "            plt.show()  \n",
    "\n",
    "        f = open(file_path+file_name, 'rb')\n",
    "        mean_value_set = np.round(np.load(f), decimals = 2)\n",
    "        alpha_set = np.round(np.load(f), decimals = 2)\n",
    "        AUC_opt = np.load(f)\n",
    "        AUC_AD = np.maximum(np.load(f), 0.5)\n",
    "        AUC_PCA = np.maximum(np.load(f), 0.5)\n",
    "        print(AUC_PCA[0,1])\n",
    "\n",
    "        plot_fig(AUC_opt, 'AUC of ideal')\n",
    "        plot_fig(AUC_AD/AUC_opt, 'AUC of EW over AUC of ideal')\n",
    "        plot_fig(AUC_PCA/AUC_opt, 'AUC of PCA over AUC of ideal')\n",
    "        plot_fig(AUC_AD/AUC_PCA, 'AUC of EW over AUC of PCA')\n",
    "\n",
    "    def generate_data_for_scatter_plot(self, file_path = \"\", file_name = \"\", num_exper=200, r_range = [1, 10], mean_value_range = [1, 10], p_o_range = [0.5, 1], p_a_range = [0, 0.3], alpha_range = [0, 1], force=True):\n",
    "        self.file_path = file_path\n",
    "        self.file_name = file_name\n",
    "        if (not force):\n",
    "            return\n",
    "        \n",
    "        num_exper = 1000\n",
    "        AUC_opt = np.zeros(num_exper)\n",
    "        AUC_AD = np.zeros(num_exper)\n",
    "        AUC_PCA = np.zeros(num_exper)\n",
    "        AUC_RMF = np.zeros(num_exper)\n",
    "        AUC_DRMF = np.zeros(num_exper)\n",
    "\n",
    "        F_opt = np.zeros(num_exper)\n",
    "        F_AD = np.zeros(num_exper)\n",
    "        F_PCA = np.zeros(num_exper)\n",
    "        F_RMF = np.zeros(num_exper)\n",
    "        F_DRMF = np.zeros(num_exper)\n",
    "\n",
    "        max_opt = np.zeros(num_exper)\n",
    "        max_AD = np.zeros(num_exper)\n",
    "        max_PCA = np.zeros(num_exper)\n",
    "        max_RMF = np.zeros(num_exper)\n",
    "        max_DRMF = np.zeros(num_exper)\n",
    "\n",
    "        parameters = []\n",
    "\n",
    "        start = 0\n",
    "        for T in range(start, num_exper):\n",
    "            r = np.random.randint(r_range[0], high=r_range[1]+1)\n",
    "            mean = np.random.uniform(mean_value_range[0], mean_value_range[1])\n",
    "            p_o = np.random.uniform(p_o_range[0], p_o_range[1])\n",
    "            p_a = np.random.uniform(p_a_range[0], p_a_range[1])\n",
    "            alpha = np.random.uniform(alpha_range[0], alpha_range[1])\n",
    "\n",
    "            self.synthetic_data(self.n1, self.n2, r, mean, p_o)\n",
    "            noise = Exponential_noise_model(p = p_a, exp_rate = 1/alpha, p_range = (0.01, 0.5), one_over_exp_range=(0.01, 0.9))\n",
    "            self.add_noise(noise)\n",
    "            self.ideal_ROC()\n",
    "            self.AD_algorithm(gamma = self.n1/r*0.5, r_constraint = self.r, debug=False, do_SVD = False)\n",
    "            self.DRMF(10, 0.3)\n",
    "            AUC_opt[T] = count_AUC(self.FPR_opt, self.TPR_opt)\n",
    "            AUC_AD[T] = np.maximum(0.5, count_AUC(self.FPR_AD, self.TPR_AD))\n",
    "            AUC_DRMF[T] = np.maximum(0.5, count_AUC(self.FPR_DRMF, self.TPR_DRMF))\n",
    "            F_opt[T] = 0\n",
    "            F_AD[T] = entry_Frobenious(self.M, self.M0)\n",
    "            F_DRMF[T] = entry_Frobenious(self.DRMF_M, self.M0)\n",
    "            max_opt[T] = 0\n",
    "            max_AD[T] = entry_max(self.M, self.M0)\n",
    "            max_DRMF[T] = entry_max(self.DRMF_M, self.M0)\n",
    "\n",
    "            # print('Frobenious AD', entry_Frobenious(self.M, self.M0))\n",
    "            # print('Frobenious DRMF', entry_Frobenious(self.DRMF_M, self.M0))\n",
    "\n",
    "            # print('max norm AD', entry_max(self.M, self.M0))\n",
    "            # print('max norm DRMF', entry_max(self.DRMF_M, self.M0))\n",
    "            #self.PCA_with_M(self.M0)\n",
    "\n",
    "            self.Robust_PCA(gamma = (self.n2/r*0.5/2), r_constraint=self.r)\n",
    "            AUC_PCA[T] = np.maximum(0.5, count_AUC(self.FPR_PCA, self.TPR_PCA))\n",
    "            max_PCA[T] = 0\n",
    "            F_PCA[T] = 0\n",
    "            for M in self.RPCA_M:\n",
    "                max_PCA[T] += entry_max(M, self.M0) / len(self.RPCA_M)\n",
    "                F_PCA[T] += entry_Frobenious(M, self.M0) / len(self.RPCA_M)\n",
    "\n",
    "            self.Robust_PCA(gamma = (self.n2/r*0.5/2), r_constraint=self.r, up_M = np.max(self.M0)*12, up_A = np.max(self.M0)*12)\n",
    "            AUC_RMF[T] = np.maximum(0.5, count_AUC(self.FPR_PCA, self.TPR_PCA))\n",
    "            max_RMF[T] = 0\n",
    "            F_RMF[T] = 0\n",
    "            for M in self.RPCA_M:\n",
    "                max_RMF[T] += entry_max(M, self.M0) / len(self.RPCA_M)\n",
    "                F_RMF[T] += entry_Frobenious(M, self.M0) / len(self.RPCA_M)\n",
    "            #self.PCA_with_M(self.M0+0.3*np.sqrt(self.M0)*np.random.normal(size=self.M0.shape))\n",
    "\n",
    "\n",
    "            #for M in self.RPCA_M:\n",
    "            #    print('Frobenious PCA', entry_Frobenious(M, self.M0))\n",
    "\n",
    "            #AUC_PCA[T] = count_AUC(self.FPR_PCA_M0, self.TPR_PCA_M0)\n",
    "            #AUC_PCA[T] = count_AUC(self.FPR_PCA, self.TPR_PCA)\n",
    "\n",
    "            parameters.append((r, mean, p_o, p_a, alpha))\n",
    "\n",
    "            print('In the step {}, AUC_opt is {}, AUC_AD is {}, AUC_PCA is {}, AUC_DRMF is {}'.format(T, AUC_opt[T], AUC_AD[T], AUC_PCA[T], AUC_DRMF[T]))\n",
    "            print('r is {}, mean is {}, p_o is {}, p_a is {}, alpha is {}'.format(r, mean, p_o, p_a, alpha))\n",
    "\n",
    "            print('Frobenious norm: AD {}, DRMF {}, RMF {}, PCA {}'.format(np.mean(F_AD[:T+1]), np.mean(F_DRMF[:T+1]), np.mean(F_RMF[:T+1]), np.mean(F_PCA[:T+1])))\n",
    "            print('max norm: AD {}, DRMF {}, RMF {}, PCA {}'.format(np.mean(max_AD[:T+1]), np.mean(max_DRMF[:T+1]), np.mean(max_RMF[:T+1]), np.mean(max_PCA[:T+1])))\n",
    "            print('AUC: AD {}, DRMF {}, RMF {}, PCA {}'.format(np.mean(AUC_AD[:T+1]), np.mean(AUC_DRMF[:T+1]), np.mean(AUC_RMF[:T+1]), np.mean(AUC_PCA[:T+1])))\n",
    "\n",
    "\n",
    "            if (T % 10 == 0 or T == num_exper - 1):\n",
    "                print('In the step {}, saving data...'.format(T))\n",
    "                if not os.path.exists(file_path):\n",
    "                    os.makedirs(file_path)\n",
    "                f = open(file_path+file_name, 'wb')\n",
    "                np.save(f, parameters)\n",
    "                np.save(f, AUC_opt)\n",
    "                np.save(f, AUC_AD)\n",
    "                np.save(f, AUC_DRMF)\n",
    "                np.save(f, AUC_RMF)\n",
    "                np.save(f, AUC_PCA)\n",
    "                np.save(f, F_AD)\n",
    "                np.save(f, F_DRMF)\n",
    "                np.save(f, F_RMF)\n",
    "                np.save(f, F_PCA)\n",
    "                np.save(f, max_AD)\n",
    "                np.save(f, max_DRMF)\n",
    "                np.save(f, max_RMF)\n",
    "                np.save(f, max_PCA)\n",
    "                #self.plot_scatter()\n",
    "            # if (T % 20 == 0 or T == num_exper - 1):\n",
    "            #     print('In the step {}, saving data...'.format(T))\n",
    "            #     if not os.path.exists(file_path):\n",
    "            #         os.makedirs(file_path)\n",
    "            #     f = open(file_path+file_name, 'wb')\n",
    "            #     np.save(f, parameters)\n",
    "            #     np.save(f, AUC_opt)\n",
    "            #     np.save(f, AUC_AD)\n",
    "            #     np.save(f, AUC_DRMF)\n",
    "            #     self.plot_scatter()\n",
    "\n",
    "    def plot_scatter(self, data = 'synthetic', file_path = \"\", file_name = \"\"):\n",
    "        \n",
    "        if (file_name == \"\"):\n",
    "            file_name = self.file_name\n",
    "            file_path = self.file_path\n",
    "\n",
    "        f = open(file_path+file_name, 'rb')\n",
    "        parameters = np.load(f)\n",
    "        AUC_opt = np.load(f)\n",
    "        AUC_AD = np.maximum(np.load(f), 0.5)\n",
    "        AUC_PCA = np.maximum(np.load(f), 0.5)\n",
    "        print(np.mean(AUC_opt))\n",
    "        print(np.mean(AUC_AD))\n",
    "        print(np.mean(AUC_PCA))\n",
    "        print(len(parameters))\n",
    "\n",
    "        plt.plot(AUC_AD, AUC_opt, 'bo', [0, 1], [0, 1], 'tab:orange', AUC_AD, AUC_PCA, 'go', linewidth=4.0)\n",
    "        plt.xlim([0.5, 1])\n",
    "        plt.ylim([0.5, 1])\n",
    "        plt.xlabel(r'AUC of $\\pi^{\\mathrm{EW}}$')\n",
    "        plt.ylabel(r'AUC')\n",
    "        plt.legend([r'($\\pi^{\\mathrm{EW}}$, $\\pi^{\\mathrm{ideal}}$)', r'($\\pi^{\\mathrm{EW}}$, $\\pi^{\\mathrm{EW}}$)', r'($\\pi^{\\mathrm{EW}}$, Robust PCA)'])\n",
    "        plt.savefig(file_path+'AUC-'+data+'.eps')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code can provide the synthetic setup with 1000 repetitions. \n",
    "Report four different algortihms on three metrics: ACU, Frobenious norm, and max norm. \n",
    "\n",
    "For Stable-PCP, we optimize lambda and mu for plotting a curve. We do so by first enumerate the ratio = lambda / mu, and then scaling for fitting the rank constraint. \n",
    "\n",
    "For RMC: the algorithm is implemented based on Stable-PCP, with projection on the max norm constraints ($|M|_{oo} \\leq a, |S|_{oo} \\leq a$)\n",
    "\n",
    "For DRMF: we implement the algorithm with the maximal rank-constraint, and maximal p_a constraint. \n",
    "\n",
    "All metrices are measured based on the average. "
   ]
  },
  {
   "source": [
    "## Synthetic Experiment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "r = 3\n",
    "np.random.seed(3)\n",
    "experiment = Experiment(n1=n, n2=n, r=r, mean_value=1, prob_observing = 0.5)\n",
    "experiment.generate_data_for_scatter_plot(file_path = 'results/06-04-beer/', file_name = 'synthetic_data.npy', force=True)\n",
    "#experiment.plot_scatter()\n",
    "#experiment.real_data()\n",
    "#experiment.generate_data_for_heat_map(l1=2, l2=2, force=False)\n",
    "\n",
    "#experiment.plot_heat_map(file_path = 'results/05-20/', file_name = 'synthetic-n=100-r=3-heat_map_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#r is 2, mean is 7.690840760524146, p_o is 0.8243170706184999, p_a is 0.224935479196669, alpha is 0.7110836066501481\n",
    "#r is 1, mean is 5.8226985649490866, p_o is 0.7046509316108835, p_a is 0.04416386204681395, alpha is 0.09484103200079186\n",
    "\n",
    "\n",
    "n = 100\n",
    "r = 5\n",
    "mean_value = 3\n",
    "prob_observing = 0.7\n",
    "np.random.seed(1)\n",
    "experiment = Experiment(n1=n, n2=n, r=r, mean_value=mean_value, prob_observing = prob_observing)\n",
    "noise = Exponential_noise_model(p = 0.1, exp_rate = 1/0.2, p_range = (0.01, 0.5), one_over_exp_range=(0.01, 0.8))\n",
    "experiment.add_noise(noise)\n",
    "experiment.ideal_ROC()\n",
    "experiment.AD_algorithm(gamma = (n/r*0.5), r_constraint = r, debug=True, do_SVD = False, using_ideal_parameter=False)\n",
    "experiment.PCA_with_M(experiment.M0)\n",
    "#experiment.Robust_PCA(gamma = (n/r*0.5/2)*3, r_constraint=r, debug = True, num_points=100, l_range=(0.5, mean_value))\n",
    "#print(noise_to_signal(experiment.M, experiment.M0*(1-noise.p+noise.p/noise.exp_rate), experiment.Ω))\n",
    "experiment.plot_ROC()"
   ]
  },
  {
   "source": [
    "## Real Experiment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "#if (experiment.data_type != 'beer_data'):\n",
    "experiment = Experiment()\n",
    "experiment.real_data()\n",
    "print(experiment.mean_value)\n",
    "noise = Exponential_noise_model(p = 0.04, exp_rate = 1/0.2, p_range = (0.01, 0.5), one_over_exp_range=(0.01, 0.8))\n",
    "#experiment.add_noise(noise)\n",
    "experiment.ideal_ROC()\n",
    "experiment.AD_algorithm(gamma = 200, r_constraint = experiment.r, debug=True, do_SVD = False, using_ideal_parameter=False)\n",
    "experiment.PCA_with_M(experiment.M0)\n",
    "#experiment.Robust_PCA(gamma = 50, r_constraint=experiment.r)\n",
    "#print(noise_to_signal(experiment.M, experiment.M0*(1-noise.p+noise.p/noise.exp_rate), experiment.Ω))\n",
    "experiment.plot_ROC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}